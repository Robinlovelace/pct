---
title: "Estimating extra cycling potential from aggretate flows"
author: "Robin Lovelace"
date: "February 13, 2015"
output:
  pdf_document:
    fig_caption: yes
---

```{r, warning=FALSE, message=FALSE, results='hide', echo=FALSE}
# output: word_document
# For reproducible results see https://github.com/Robinlovelace/pct
pkgs <- c("png", "grid", "ggmap", "ggthemes", "knitr", "nplr")
lapply(pkgs, library, character.only = TRUE)
opts_knit$set(root.dir = "../")
```

There are many ways to characterise distance decay (*DD*),
the relationship between the distance
of a trip and the probability of it being made by a particular mode --- in this
case by bicycle. In this document we see how *DD* can be estimated
using flow data from the Census. Clearly
(as illustrated by the growth of long-distance bicycle touring) *all* trips
are cyclable in theory. In practice, however, short trips are far more likely
to be cycled than longer trips for reasons including time, stamina and comfort.
This fact is represented in the flow data (Figure 1). The challenge is extracting the
nature of *DD* from the flow data, which is rather opaque in its raw form.

```{r, fig.cap="Plot of the demonstration city (Leeds) with all cycle trip flows represented by the white lines (oppacity is proportional to bicycle commuters).", echo=FALSE}
source("case-studies/leeds.R")
img <- readPNG("figures/leeds-flow-bicycle.png")
grid.raster(img)
```

Building on 'the principle of parsimony' --- otherwise known as Occam's razor ---
we will start with the simplest model that explains *DD* in active
travel reasonably well This is log-linear decay, characterised by two parameters
(Iacono, 2010). We will build on this example to explore alternative
distance-decay functions.

# Estimating distance decay

A problem with the log-linear function
(and any log-model) for fitting to raw flow data on cycling is that
the log of zero is minus infinity ($log(0) = -\infty$) yet 0 flows between
origins and destinations are common for all modes of transport, and especially
so for rare modes. Of the 589 positive commuter flow lines between 25 MSOA zones 
surrounding Leeds city centre, for example, more than half (389) have 0 cyclists.
Zero and one-inflation
clearly poses a problem to efforts to parameterise *DD* through linear
regression: it is hard to estimate the parameters that result in infinity!

In addition, because flow matrices are so sparse, counts of 1 are common.
Thus both extreme values of
0 and 1 values are excessively common (or *inflated*) in raw flow data, 
as illustrated in Figure 2. This means that fitting non-probabilistic
regression models to the flow-level is problematic.

```{r, fig.height=3, fig.width=4, fig.cap="Scatterplot of flow distance and proportion cycling illustrating the frequency of 0s and 1s in the proportion of commutes by bicycle. Data: Leeds (n = 10,242).", echo=FALSE}
plot(flow$dist, flow$pcycle, xlab = "Distance (miles)", ylab = "% commutes by bike") 
# the problem with flow data: many 0's and 1's
```

There are at least two viable solutions to this problem:

1. Aggregating flows into distance bins such so that we estimate the *average*
(or population-weighted average) proportion of trips made by bicycle.
2. Zero-inflated regression, whereby the high frequency of zeros in the dependent
variable (% commuting by bicycle) is accounted for in the model.

Both solutions have advantages. Binning greatly reduces the computational requirements
of the model by grouping hundreds of distances into only a few dozen bins (how
many bins depends on the bin size). Binning is therefore
useful for parameter estimation. However, the binning approach cannot predict
the rate of flow between individual OD pairs, so cannot realistically be
used to estimate *ECP* for OD flows. Zero-inflated regression, by contrast,
can estimate OD-flows but is more computationally intensive.

## Binning flows by distance

### Binning distances

Distance in the flow data is calculated as the Euclidean distance
(a refinement would be to use route distance)
between origin and destination centroids and is a truly continuous variable.
This differs from the individual-level survey data which treats distance
as a quasi-continuous variable with a granularity of 0.1 miles (and clumping
around integer distances, which impacts on our selection of distance bins).
We bin the distances as follows, and set the maximum distance to 20.5 miles:

```{r}
brks <- c(0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 9.5, 12.5, 15.5, 20.5)
flow <- flow[flow$dist < 20.5, ]
```

This allows for the OD flows to be grouped by distance and for the creation
of aggregates for each distance band:

```{r}
flow$binned_dist <- cut(flow$dist, breaks = brks, include.lowest = T)

# Create aggregate variables
gflow <- group_by(flow, binned_dist) %>%
  summarise(mdist = mean(dist), mbike = mean(pcycle),
    total = sum(All.categories..Method.of.travel.to.work))
gflow$nbike <- gflow$total * gflow$mbike / 100 # number of bikes in each zone
```


### Defining average distances per bin

The simplest approach to setting the distance associated with each bin
score is to take the mid-point between the upper and lower value of each bin:

```{r}
brks_min <- head(brks, -1)
brks_max <- brks[-1]
(midpoint <- (brks_min +brks_max) / 2)
```

However this is an oversimplification: distance distributions are strongly
positively skewed so the average of distances within the further distance bands
are likely to be substantially lower than the mean. This is true of our case
study city (Figure 3), therefore we use the computed mean distance for each bin:

```{r, fig.height=3, fig.width=4, fig.cap="The relationship between bin midpoint and average Euclidean distance of trips within each bin."}
plot(gflow$mdist, midpoint, xlab = "Mean distance (miles)")
abline(a = 0, b = 1)
```

The overall number of trips per distance band is illustrated in Figure 4.
The barely visible grey fill at the bottom of the bars represents bicycle
trips. Unsurprisingly, these all-but disappear after 6 miles, demonstrating
that distance decay for cycling is faster than for trips overall.

```{r, echo=FALSE, fig.cap="Number of trips overall per distance band (white) and number of bicycle trips per distance band (grey)."}
tb <- sum(gflow$total)
ggplot(data = gflow) + 
  geom_histogram(aes(x = midpoint, y = ..density.. * 234968, weight = total),
  position = "identity", breaks = brks, fill = "white", colour = "black") +
    geom_histogram(aes(x = midpoint, y = ..density.. * 4648, weight = nbike),
  position = "identity", breaks = brks, alpha = 0.2) +
  ylab("Number of trips per bin") + xlab("Distance (miles)") +
  theme_bw()
```


### The relationship between distance and cycling in grouped data

Now the data have been grouped and assigned to approximate distances,
we can use regression to explore **DD** for cycling.
The relationship is strikingly curvilinear in the example city.
With this non-linear relationship in mind (with a peak around 3 miles),
we fitted various log-linear, quadratic and cubic functional forms to the data.

```{r}
mod_loglin <- lm(log(mbike) ~ mdist, data = gflow)
mod_logsqr <- lm(log(mbike) ~ mdist + I(mdist^2), data = gflow)
mod_logcub <- lm(log(mbike) ~ mdist + I(mdist^2) + I(mdist^3), data = gflow)
mod_cub <- lm(mbike ~ mdist + I(mdist^2) + I(mdist^3), data = gflow)
```

The above code fitted log-linear, log-square and log-cubic functional forms to the
data. The following code runs **weighted regression**.
Adding weights to the regression in this way reduces the impact of
the longer-distance commutes, which fewer cyclists make. Note that two weight
vectors are used: total number of trips and total number of cyclists.
The results of these regressions are presented in Figure 5.

```{r}
modw_logcub <- lm(log(mbike) ~ mdist + I(mdist^2) + I(mdist^3),
  weights = total, data = gflow)
modw2_logcub <- lm(log(mbike) ~ mdist + I(mdist^2) + I(mdist^3),
  weights = nbike, data = gflow)
```

```{r, fig.cap="Linear regression to estimate *DD* from flow data. Blue, red and green lines represent log-linear, quadratic and cubic functional forms, respectively. The dotted and dashed green lines represent the impact of weighting but the number of total and cyclist commuter trips in each category, respectively.  The black line is the cubic regression, without taking the log of y.", echo=FALSE}
plot(gflow$mdist, gflow$mbike,
  xlab = "Distance (miles)", ylab = "Percent cycling", ylim = c(0, 3))
lines(gflow$mdist, exp(mod_loglin$fitted.values), col = "blue")
lines(gflow$mdist, exp(mod_logsqr$fitted.values), col = "red")
lines(gflow$mdist, exp(mod_logcub$fitted.values), col = "green")
lines(gflow$mdist, exp(modw_logcub$fitted.values), col = "green", lty = 2)
lines(gflow$mdist, exp(modw2_logcub$fitted.values), col = "green", lty = 3)
lines(gflow$mdist, mod_cub$fitted.values, col = "black", lty = 4)
```

Does the log-term make any difference to model fit? A little, but not much
for the Leeds dataset.

From visual inspection of the models, the log-cubic model clearly fits better.
This is also apparent from the adjusted R-squared scores of each model
(which takes accound of over-fitting through excessive free parameters):
The log-cubic model explains around 90% of variation in the average
proportion of people who cycle in different distance groups:

```{r, echo=FALSE}
mnames <- ls()[grep("mod_", ls())]
mods <- data.frame(Model = mnames, Adj.R.sq = NA)
for(i in 1:nrow(mods)){
  mods$Adj.R.sq[i] <- summary(get(mnames[i]))$adj.r.squared
  # round(summary(get(mnames[i]))$coef, digits = 3 )[,1]
}
kable(mods, digits = 3)
```


```{r, echo=FALSE}
# summary(modw_logcub)
# plot(gflow$mdist, gflow$mbike,
#   xlab = "Distance (miles)", ylab = "Percent cycling")
# lines(gflow$mdist, exp(modw_loglin$fitted.values), col = "blue")
# lines(gflow$mdist, exp(modw_logsqr$fitted.values), col = "red")
# ```{r, fig.cap="Weighted regression results to estimate *DD* from flow data. Blue, red and green lines represent log-linear, quadratic and cubic functional forms, respectively."}
# old <- setwd("../")
# img <- readPNG("figures/weighted-reg.png")
# grid.raster(img)
# ```
```


```{r, echo=FALSE}

# 
# 
# ## Zero-inflated regression
```

### Estimating propensity to cycle based on individual flows

There are issues with fitting the regression model to the grouped data.
Using grouped data precludes the inclusion of flow-level variables that could
be useful in acurately estimating the potential level of cycling (CLC)
such as steepness and the characteristics of the origin zone.

We can fit exactly the same model to the individual-level data:

```{r, fig.cap="Distance decay curves based on the cubic polynomial regression against distance for all flows (red lines)"}
flow$clc <- flow$Bicycle / flow$All.categories..Method.of.travel.to.work
mod_ind1 <- lm(pcycle ~ dist + I(dist^2) + I(dist^3), data = flow)
mod_ind2 <- lm(pcycle ~ dist + I(dist^2) + I(dist^3), data = flow,
  weights = All.categories..Method.of.travel.to.work)
f3 <- flow[flow$dist < 15, ]
mod_ind3 <- lm(pcycle ~ dist + I(dist^2) + I(dist^3), data = f3,
  weights = All.categories..Method.of.travel.to.work)
summary(mod_ind1)
df <- data.frame(dist = seq(0.1, max(flow$dist), length.out = 100))
df2 <- data.frame(mdist = seq(0.1, max(flow$dist), length.out = 100))

plot(flow$dist, flow$pcycle, xlim = c(0, 16), ylim = c(0, 3),
  xlab = "Distance (km)", ylab = "Percentage cycling")
lines(df$dist, predict(object = mod_ind1, df), col = "red", lwd = 4)
lines(df$dist, predict(object = mod_ind2, df), col = "red", lwd = 6, lty = 2)
lines(df$dist, predict(object = mod_ind3, df), col = "red", lwd = 6, lty = 3)
lines(df2$mdist, exp(predict(object = modw_logcub, df2)),
  col = "green", lwd = 5)
lines(gflow$mdist, mod_cub$fitted.values, col = "black", lty = 4, lwd = 6)
```

## Regression against the cumulative probability of cycling

To reduce the noise in the data arising from 0s and 1s, the rate of
cycling can be viewed as a cumulative distribution of trips with distance:

```{r}
fc <- flow[ order(flow$dist), ] 
head(fc$dist)
head(cumsum(fc$Bicycle)) # cumulative distances
fc$cumclc <- cumsum(fc$Bicycle) / sum(fc$Bicycle)
```

We can fit a  logistic regression model to this data.

```{r}
plot(fc$dis, fc$cumclc)
mod_logist1 <- glm(cumclc ~ dist, family = "binomial", weights = fc$All.categories..Method.of.travel.to.work, data = fc)
lines(fc$dist, mod_logist1$fitted.values, col = "red", lwd = 4)
summary(mod_logist1)
```

Note the quality of the fit and the simplicity of the data, compared
with the non-cumulative distribution of proportion cycling with distance.
The challenge is converting this into a distance decay function.

```{r, eval=F}
mod_logist2 <- nplr(fc$dist, fc$cumclc)
mod_logist3 <- nplr(fc$dist, fc$cumclc, useLog = F)
mod_logist4 <- nplr(fc$dist, fc$cumclc, npars = 2)
mod_logist5 <- nplr(fc$dist, fc$cumclc, npars = 3)
plot(mod_logist4) 
```

```{r, echo=FALSE}
img <- readPNG("figures/2-param-nplr.png")
grid.raster(img)
```


The best in terms of simplicity seems to be the 4th model:

```{r, eval = F}
mod_logist4
# Instance of class nplr
# 
# 2-P logistic model
# Bottom asymptote: 0 
# Top asymptote: 1 
# Inflexion point at (x, y): 3.426146 0.5 
# Goodness of fit: 0.9947746 
# Standard error: 0.0205036 
getPar(mod_logist4)
# $npar
# [1] 2
# 
# $params
#   bottom top     xmid     scal s
# 1      0   1 3.426146 3.192967 1
```






